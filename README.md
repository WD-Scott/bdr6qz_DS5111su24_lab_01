# bdr6qz_DS5111su24_lab_01
Wyatt Scott's (bdr6qz) repo for DS5111 Labs

![Static Badge](https://img.shields.io/badge/Python_package%3A-passing-blue?style=flat&logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAAC0AAAAiCAMAAAD8kqB9AAAClFBMVEUAAAD%2F%2F%2F%2FBYzTCysr2WxvyQRLnSibjUy3VZSLbQyvSjHHIjEX5%2F%2F%2F5%2B%2FvIz9D8%2F%2F%2F4WhryWRz3QBHxUR7ySh%2FxbBjsTiHwbxnnTCXVQiz96eTg4N%2Fd3dzL0tH0XDPFzc32SRv0UB%2F3WRr4XRn1SR32VBv1Uhz0TB71URz0QBDySh3%2FYAP4ZxT1YxnwXRz0ZxnvTh7vVR7yPhDxQhfrTB%2FcVCLfRSzUUCfdPCbLciPQOjLu8fHc5OXn5eT85uHj4uHY19bKt6%2F3WBv2Uhv0WS%2F1TSDyWjT0Sx33XBr3Vhv0Vxz3XRr3Xhr1Uhv0Ux30SRv0Whv3Yhn2Xhr0UhzzPg%2F2RBb0Tx7zPg%2FzPg7zUR33YxjyTh%2F7XgL6WQDxTh%2FwVB%2F3Pw%2FzPA3wTh7zYRv1aBntTCDxXhzrTx%2FwSh7oYCDxaxjuTiDmSyHsWR7rPxnoQiXnchrmehr%2B9%2FTs7%2FD%2B7unW2djQ19jm2dbHxcLKuLD3v6%2FJrKL1SRvvelv25ePBxML7aRfg7%2FbS5ezY7PDA1t32VBv2UBz0SR70QxT0QxT0QxT2VRv1VRz3Yhn1Sx34VRvyTB%2F1Sh71Rhj2Uhz2TBj3YRn3Yxn1RBb5ZBfxTB%2F2ZBn7Zgz4Zhj4QhPuWB30ZBrySR3yXhzvSyDvWRv3PxDvTR%2F0WRzyYhvyPQ32aRryahrvViDuYhnxQRPzbRrsRh%2FYXSPuchnrcxjRp5vqbEr5v6%2F0cU3wWDD849vQqqD3pI32n4b2moDfhmznlmTocVD0XjX5Vhrl5ubKtKvirZ%2FPpprTpZbWnI%2F8q3z2lnv4lHn5pXXwn27fhGrfgmjlkF%2F5klzmclPjcFD1bUn0Z0Ptd0H3bDb0VCr0WyT4WRn7YRf4PQvBMCeZAAAAs3RSTlMA%2FQj72VQnHBIPBgX%2B%2Fv78%2BKqajGI0LyolBv7%2B%2Fv79%2FPX09PTu287Cv7%2B1oqCTi394c1pONCIYFRINCv7%2B%2Fv7%2B%2Fv79%2Ffv39fHw7evp4uHS0M%2FMysXFwbq4s7Cwq6SimpGQgX59eHJoYFlRUElHRD8sGRX%2B%2Fv7%2B%2Fv7%2B%2Fv7%2B%2Fv38%2FPv6%2Bvn57u3p4%2BLd19bV0tLNzcrIwsC5trSnp6eioJ%2Bem5uVlZWRkIiDbmlcS0tEOTQjHZlkpy4AAAI7SURBVDjLYqAPyBHU0Y6NjZlvCuZxLp%2BtrR2jI5iOS7nWjX2nT1xQ5ARzuKdc3Xf%2BzDV%2Fdlyq2dt3NvHbqUhAzJ50vKWxzi0Pt1sSttRLM25bAWYbbXd0YDwVgcflEirH%2BHi2dpoBmVyhe%2BWtd7isBTLxGM4MNDyRQZKBdXtlKf%2FJCLzBwua%2BGWh4BzsDE8RoY%2FyhuGQLsz3%2F5USg0Y4yjHvCufCrZlPYLMuztYt9%2Bjk%2BXjs5Y0JRJAQ0nHFbiNthaaDRQD4RhlfdPsvHKyXHSjj%2BhfYz2xbVVtsw7tbkIqxaAmg4b3kFwmjChh%2BSgRhNGIi57iyTKS45YIRDHiAONMMvyjvw70Iz2hzOMs3kQDX8qI3UARRXc2duQJLXW4MsN%2FdS864QJiQBUb1cZHnTeQvFETwTxSNXkFxdoCdoguZ2wwDdjXDOguvqcKMLkwOEOTG8mh%2FpoysOM7xGBMrapM8SnIM1aDL8PGat4waxJFPZIe7V9fZNlcQRklYiagKB%2BqLcEJ74yqlKqklmeGLGyjjSU3laimiB%2BCrAoryVwkTMgYGHUzHIUjMDr1sNPso3BeLZcKpjMmfisEwTzErRiQpUVurXmNgm0Dtjjn7WsuRCDqAMWvj1%2BAWxsHgcdPJUnRwnst6CwVIsQ1ij28vpoAALS5Ca6mIU1aujVaINklp9s%2FMtkEQ52fKCneMN4tzDDNGcsmiCsIZzGoYLcxXVhNW1mNCFLZb6q2MrILO1%2BmZKYPMorlBlIBcAACpxj1lvNSqgAAAAAElFTkSuQmCC&labelColor=%23232D4B&color=%23E57200) &nbsp; &nbsp; &nbsp;[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

<details>
<summary><h1 style="font-size: 16px;">Manifest</h1></summary>

### makefile

### README.md

### License

### pytest.ini

<details>
<summary><h3 style="font-size: 14px;">tokenizer.py</h3></summary>

This Python module file contains the functions and objects available in the dropdown menus below.

<details>
<summary><strong>Click here to see the functions in tokenizer.py</strong></summary>

- `clean_text(text)`:

  Remove punctuation from the input string and convert it to lowercase.

- `tokenize(text)`:

  Split the input string into a list of words.

- `count_words(text)`:

  Count the frequency of each word in the input string.

- `run_bash(command)`:

  Run a bash command and return its output.

- `read_file(file_path)`:

  Read the contents of a file.
</details>

<details>
<summary><strong>Click here to see the objects in tokenizer.py</strong></summary>

- text

  Testing sentence from The Raven.

- text_dict

  Dictionary of `text` testing sentence to compare with `count_words` output.

- test_list

  List of `text` testing sentence to compare with `tokenize` output.

- books_dir

  The path for the `books` directory (available only after a user runs `make get_texts`).

- books_paths

  Dictionary of the necessary book filepaths inside of `books_dir`.

- TheRaven

  The text of The Raven.
    
- FalloftheHouseofUsher

  The text of Fall of the House of Usher.

- CaskofAmontillado

  The text of Cask of Amontillado.

- ThePoems

  The text of The Poems.

- test_cases

  List of test files for testing the functions against all English texts.

- test_ids

  List of names in test cases for cleaner output of parameterized functions.
</details>
</details>

<details>
<summary><h3 style="font-size: 14px;">Tests.py</h3></summary>
    
This directory contains Python module files for testing the functions in `tokenizer.py`.

#### - `test_count_words.py`

<details>
<summary><strong>Click here to see the functions in test_count_words.py</strong></summary>

- `test_count_words()`:

  Test `count_words`.

- `test_fail_count_words()`:

  Purposefully fail when testing `count_words`.

- `test_bash_count_words()`:

  Test `count_words` using bash.

- `test_count_words_skipper()`:

  Test function to show pytest mark and skipping.

- `test_all_count_words()`:

  Test `count_words` on all the English texts.

- `test_corbeau_count_words()`:

  Tests `count_words` against snippet from Le Corbeau
</details>

#### - `test_tokenizer.py`

<details>
<summary><strong>Click here to see the functions in test_tokenizer.py</strong></summary>

- `test_tokenize()`:

  Test `tokenize`.

- `test_fail_tokenize()`:

  Purposefully fail when testing `tokenize`.

- `test_bash_tokenize()`:

  Test `tokenize` using bash.

- `test_tokenize_skipper()`:

  Test function to show pytest mark and skipping.

- `test_all_tokenize()`:

  Test `tokenize` on all the English texts.

- `test_corbeau_tokenize()`:

  Tests `tokenize` against snippet from Le Corbeau
</details>

#### - `test_clean_text.py`

<details>
<summary><strong>Click here to see the functions in test_clean_text.py</strong></summary>

- `test_clean_text()`:

  Test `clean_text`.

- `test_fail_clean_text()`:

  Purposefully fail when testing `clean_text`.

- `test_bash_clean_text()`:

  Test `clean_text` using bash.

- `test_clean_text_skipper()`:

  Test function to show pytest mark and skipping.

- `test_all_clean_text()`:

  Test `clean_text` on all the English texts.

- `test_corbeau_clean_text()`:

  Tests `clean_text` against snippet from Le Corbeau.
</details>

#### - `test_complicated.py`

<details>
<summary><strong>Click here to see the functions in test_complicated.py</strong></summary>

- `test_get_texts()`:

  Tests the `make get_texts` job from the makefile.
  
- `test_tokenizer_count_raven()`:

  Tests the main functions from tokenizer.py together.

</details>
</details>
</details>

<details>
<summary><h1 style="font-size: 16px;">Minimal Reproducible Code</h1></summary>

### Getting Started:

To get started, clone this repo and in the Command Line run:

```
make setup
```

This will create a virtual environment with Python 3 and install the required packages stored in `requirements.txt`.

### Downloading Books

To download the books, in the Command Line you can run:

```
make get_texts
```

This will create a new directory, `books`, within which it will download the specified books by Edgar Allan Poe.

### Checking various characteristics of the books

The makefile includes several jobs that allow you to check difference characteristics of the now-downloaded books. To see how many words are in "The Raven," for example, you can run:

```
make raven_word_count
```
